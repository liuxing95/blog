---
title: 'Mastra Scorers'
date: '2025-11-11'
excerpt: 'Mastra Scorers å®Œæ•´æ•™ç¨‹'
tags: ['Agent', 'Mastra']
series: 'Agent'
---

# Mastra Scorers å®Œæ•´æ•™ç¨‹

## ç›®å½•

1. [Scorers æ¦‚è¿°](#scorers-æ¦‚è¿°)
2. [è¯„ä¼°ç®¡é“æ¶æ„](#è¯„ä¼°ç®¡é“æ¶æ„)
3. [å†…ç½® Scorers](#å†…ç½®-scorers)
4. [è‡ªå®šä¹‰ Scorers](#è‡ªå®šä¹‰-scorers)
5. [Live è¯„ä¼°](#live-è¯„ä¼°)
6. [Trace è¯„ä¼°](#trace-è¯„ä¼°)
7. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
8. [ä¸ä¼ ç»Ÿ Evals å¯¹æ¯”](#ä¸ä¼ ç»Ÿ-evals-å¯¹æ¯”)

---

## Scorers æ¦‚è¿°

### ä»€ä¹ˆæ˜¯ Scorersï¼Ÿ

Scorers æ˜¯ç”¨äºæµ‹é‡ AI ç”Ÿæˆè¾“å‡ºçš„**è´¨é‡ã€å‡†ç¡®æ€§æˆ–æ€§èƒ½**çš„è¯„ä¼°å·¥å…·ã€‚å®ƒä»¬æä¾›äº†ä¸€ç§è‡ªåŠ¨åŒ–æ–¹å¼æ¥è¯„ä¼° Agentsã€Workflows æˆ–è¯­è¨€æ¨¡å‹æ˜¯å¦äº§ç”Ÿäº†é¢„æœŸç»“æœã€‚

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š

- **Scoreï¼ˆåˆ†æ•°ï¼‰**ï¼šæ•°å€¼ï¼ˆé€šå¸¸ 0-1ï¼‰ï¼Œé‡åŒ–è¾“å‡ºæ»¡è¶³è¯„ä¼°æ ‡å‡†çš„ç¨‹åº¦
- **Reasonï¼ˆåŸå› ï¼‰**ï¼šè§£é‡Šåˆ†æ•°çš„æ–‡æœ¬è¯´æ˜
- **Automaticï¼ˆè‡ªåŠ¨åŒ–ï¼‰**ï¼šå¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹
- **Persistentï¼ˆæŒä¹…åŒ–ï¼‰**ï¼šç»“æœè‡ªåŠ¨å­˜å‚¨åˆ°æ•°æ®åº“

### ä¸ºä»€ä¹ˆéœ€è¦ Scorersï¼Ÿ

```mermaid
graph TB
    A[AI ç³»ç»ŸæŒ‘æˆ˜] --> B[è¾“å‡ºè´¨é‡ä¸ç¨³å®š]
    A --> C[éš¾ä»¥é‡åŒ–æ€§èƒ½]
    A --> D[ç¼ºä¹æ”¹è¿›æ–¹å‘]

    E[Scorers è§£å†³æ–¹æ¡ˆ] --> F[å®¢è§‚è¯„åˆ†æŒ‡æ ‡]
    E --> G[æŒç»­è´¨é‡ç›‘æ§]
    E --> H[å¯è¿½æº¯çš„æ”¹è¿›]

    B --> F
    C --> G
    D --> H

    style A fill:#FFB6C1
    style E fill:#90EE90
```

**åº”ç”¨åœºæ™¯**ï¼š

| åœºæ™¯       | ä½¿ç”¨çš„ Scorer                        | ç›®æ ‡                   |
| ---------- | ------------------------------------ | ---------------------- |
| RAG ç³»ç»Ÿ   | Context Relevance, Faithfulness      | ç¡®ä¿æ£€ç´¢å†…å®¹ç›¸å…³ä¸”å‡†ç¡® |
| å®¢æœ Agent | Tone Consistency, Toxicity           | ä¿æŒä¸“ä¸šä¸”å®‰å…¨çš„å›å¤   |
| å†…å®¹ç”Ÿæˆ   | Completeness, Answer Relevancy       | ç”Ÿæˆå®Œæ•´ä¸”ç›¸å…³çš„ç­”æ¡ˆ   |
| ä»£ç åŠ©æ‰‹   | Tool Call Accuracy, Prompt Alignment | æ­£ç¡®é€‰æ‹©å·¥å…·å¹¶å¯¹é½éœ€æ±‚ |

---

## è¯„ä¼°ç®¡é“æ¶æ„

### å››æ­¥ç®¡é“è®¾è®¡

```mermaid
graph LR
    A[Input/Output] --> B[1. Preprocess<br/>å¯é€‰]
    B --> C[2. Analyze<br/>å¯é€‰]
    C --> D[3. Generate Score<br/>å¿…éœ€]
    D --> E[4. Generate Reason<br/>å¯é€‰]

    B -.æå–/è½¬æ¢æ•°æ®.-> F[(Results)]
    C -.åˆ†æå’Œæ´å¯Ÿ.-> F
    D -.æ•°å€¼åˆ†æ•°.-> F
    E -.è§£é‡Šè¯´æ˜.-> F

    style D fill:#FFD700
    style F fill:#87CEEB
```

### ç®¡é“æ­¥éª¤è¯¦è§£

```typescript
interface ScorerPipeline<TInput, TOutput> {
  // æ­¥éª¤ 1: é¢„å¤„ç† (å¯é€‰)
  preprocess?: (data: { run: { input: TInput; output: TOutput } }) => PreprocessResult;

  // æ­¥éª¤ 2: åˆ†æ (å¯é€‰)
  analyze?: (data: {
    run: { input: TInput; output: TOutput };
    results: { preprocessStepResult?: PreprocessResult };
  }) => AnalyzeResult;

  // æ­¥éª¤ 3: ç”Ÿæˆåˆ†æ•° (å¿…éœ€)
  generateScore: (data: {
    run: { input: TInput; output: TOutput };
    results: {
      preprocessStepResult?: PreprocessResult;
      analyzeStepResult?: AnalyzeResult;
    };
  }) => number;

  // æ­¥éª¤ 4: ç”ŸæˆåŸå›  (å¯é€‰)
  generateReason?: (data: {
    score: number;
    run: { input: TInput; output: TOutput };
    results: {
      preprocessStepResult?: PreprocessResult;
      analyzeStepResult?: AnalyzeResult;
    };
  }) => string;
}
```

### ä½•æ—¶ä½¿ç”¨å„æ­¥éª¤

```mermaid
graph TD
    A[å¼€å§‹è¯„ä¼°] --> B{æ•°æ®éœ€è¦é¢„å¤„ç†?}

    B -->|æ˜¯| C[Preprocess]
    B -->|å¦| D{éœ€è¦è¯¦ç»†åˆ†æ?}

    C --> D

    D -->|æ˜¯| E[Analyze]
    D -->|å¦| F[Generate Score]

    E --> F

    F --> G{éœ€è¦è§£é‡Š?}

    G -->|æ˜¯| H[Generate Reason]
    G -->|å¦| I[å®Œæˆ]

    H --> I

    style C fill:#FFE4B5
    style E fill:#98FB98
    style F fill:#FFD700
    style H fill:#87CEEB
```

**ä½¿ç”¨æŒ‡å—**ï¼š

| æ­¥éª¤                | ä½•æ—¶ä½¿ç”¨         | ç¤ºä¾‹åœºæ™¯                               |
| ------------------- | ---------------- | -------------------------------------- |
| **Preprocess**      | æ•°æ®å¤æ‚éœ€è¦æ¸…æ´— | æå– JSON ä¸­çš„ç‰¹å®šå­—æ®µã€åˆ†è¯ã€æ ‡å‡†åŒ–   |
| **Analyze**         | éœ€è¦ç»“æ„åŒ–åˆ†æ   | è¯†åˆ«æ‰€æœ‰å£°æ˜ã€æ£€æµ‹åè§æ¨¡å¼ã€ç»Ÿè®¡å…³é”®è¯ |
| **Generate Score**  | æ€»æ˜¯éœ€è¦         | è®¡ç®—æœ€ç»ˆåˆ†æ•°ï¼ˆ0-1ï¼‰                    |
| **Generate Reason** | éœ€è¦å¯è§£é‡Šæ€§     | å®¡è®¡ã€è°ƒè¯•ã€ç”¨æˆ·åé¦ˆ                   |

### åº•å±‚å®ç°åŸç†

```mermaid
sequenceDiagram
    participant Client
    participant Scorer
    participant Preprocess
    participant Analyze
    participant GenerateScore
    participant Storage

    Client->>Scorer: .run({ input, output })

    opt å¦‚æœå®šä¹‰äº† preprocess
        Scorer->>Preprocess: æ‰§è¡Œé¢„å¤„ç†
        Preprocess-->>Scorer: preprocessResult
    end

    opt å¦‚æœå®šä¹‰äº† analyze
        Scorer->>Analyze: æ‰§è¡Œåˆ†æ
        Analyze-->>Scorer: analyzeResult
    end

    Scorer->>GenerateScore: ç”Ÿæˆåˆ†æ•°
    GenerateScore-->>Scorer: score (0-1)

    opt å¦‚æœå®šä¹‰äº† generateReason
        Scorer->>Scorer: ç”ŸæˆåŸå› 
    end

    Scorer->>Storage: ä¿å­˜ç»“æœåˆ° mastra_scorers è¡¨
    Scorer-->>Client: ScorerResult
```

**Scorers åº•å±‚ä½¿ç”¨ Mastra Workflows**ï¼š

æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯ä¸€ä¸ª Workflow Stepï¼Œè¿™æä¾›äº†ï¼š

- âœ… å¼‚æ­¥æ‰§è¡Œ
- âœ… é”™è¯¯å¤„ç†
- âœ… çŠ¶æ€æŒä¹…åŒ–
- âœ… å¯è§‚æµ‹æ€§

---

## å†…ç½® Scorers

### Scorers åˆ†ç±»ä½“ç³»

```mermaid
mindmap
  root((å†…ç½® Scorers))
    å‡†ç¡®æ€§å’Œå¯é æ€§
      Answer Relevancy
      Answer Similarity
      Faithfulness
      Hallucination
      Completeness
      Tool Call Accuracy
      Prompt Alignment
    ä¸Šä¸‹æ–‡è´¨é‡
      Context Precision
      Context Relevance
    è¾“å‡ºè´¨é‡
      Tone Consistency
      Toxicity
      Bias
      Keyword Coverage
```

### 1. å‡†ç¡®æ€§å’Œå¯é æ€§ Scorers

#### Answer Relevancy

è¯„ä¼°å“åº”æ˜¯å¦å›ç­”äº†ç”¨æˆ·çš„é—®é¢˜ã€‚

```typescript
import { createAnswerRelevancyScorer } from '@mastra/evals/scorers/llm';
import { openai } from '@ai-sdk/openai';

const relevancyScorer = createAnswerRelevancyScorer({
  model: openai('gpt-4o-mini'),
  uncertaintyWeight: 0.3, // éƒ¨åˆ†ç›¸å…³è¯­å¥çš„æƒé‡
});

// ä½¿ç”¨ç¤ºä¾‹
const result = await relevancyScorer.run({
  input: 'ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ',
  output: 'æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ...',
});

console.log(result.score); // 0.95
console.log(result.reason); // "å“åº”ç›´æ¥å›ç­”äº†é—®é¢˜..."
```

**å·¥ä½œåŸç†**ï¼š

```mermaid
graph TB
    A[ç”¨æˆ·é—®é¢˜ + Agent å›ç­”] --> B[åˆ†è§£ä¸ºå¤šä¸ªé™ˆè¿°]
    B --> C{æ¯ä¸ªé™ˆè¿°}
    C -->|ç›´æ¥ç›¸å…³| D[æƒé‡ 1.0]
    C -->|éƒ¨åˆ†ç›¸å…³| E[æƒé‡ 0.3]
    C -->|ä¸ç›¸å…³| F[æƒé‡ 0.0]
    D --> G[åŠ æƒå¹³å‡]
    E --> G
    F --> G
    G --> H[æœ€ç»ˆåˆ†æ•°]

    style H fill:#FFD700
```

#### Faithfulness

è¡¡é‡å“åº”æ˜¯å¦å‡†ç¡®è¡¨ç¤ºæä¾›çš„ä¸Šä¸‹æ–‡ã€‚

```typescript
import { createFaithfulnessScorer } from '@mastra/evals/scorers/llm';

const faithfulnessScorer = createFaithfulnessScorer({
  model: openai('gpt-4o-mini'),
  context: ['2024å¹´å…¨çƒ AI å¸‚åœºè§„æ¨¡è¾¾åˆ° 1840 äº¿ç¾å…ƒ', 'ChatGPT åœ¨ 2022 å¹´ 11 æœˆå‘å¸ƒ'],
});

const result = await faithfulnessScorer.run({
  input: 'AI å¸‚åœºæœ‰å¤šå¤§ï¼Ÿ',
  output: 'AI å¸‚åœºåœ¨ 2024 å¹´è¾¾åˆ° 1840 äº¿ç¾å…ƒ',
});

console.log(result.score); // 1.0 (å®Œå…¨å¿ å®äºä¸Šä¸‹æ–‡)
```

#### Hallucination

æ£€æµ‹äº‹å®çŸ›ç›¾å’Œæœªç»æ”¯æŒçš„å£°æ˜ã€‚

```typescript
import { createHallucinationScorer } from '@mastra/evals/scorers/llm';

const hallucinationScorer = createHallucinationScorer({
  model: openai('gpt-4o-mini'),
  context: ['è‹¹æœå…¬å¸æˆç«‹äº 1976 å¹´'],
});

// å¹»è§‰ç¤ºä¾‹
const result = await hallucinationScorer.run({
  input: 'è‹¹æœå…¬å¸ä½•æ—¶æˆç«‹ï¼Ÿ',
  output: 'è‹¹æœå…¬å¸æˆç«‹äº 1985 å¹´', // ä¸ä¸Šä¸‹æ–‡çŸ›ç›¾
});

console.log(result.score); // æ¥è¿‘ 1.0 (æ£€æµ‹åˆ°å¹»è§‰)
```

### 2. ä¸Šä¸‹æ–‡è´¨é‡ Scorers

#### Context Precision vs Context Relevance

```mermaid
graph TB
    subgraph "Context Precision"
        A1[å…³æ³¨é¡ºåºå’Œæ’å]
        A2[ä½¿ç”¨ MAP æŒ‡æ ‡]
        A3[å¥–åŠ±ç›¸å…³å†…å®¹å‰ç½®]
    end

    subgraph "Context Relevance"
        B1[å…³æ³¨å®é™…ä½¿ç”¨æƒ…å†µ]
        B2[è¿½è¸ªä¸Šä¸‹æ–‡åˆ©ç”¨ç‡]
        B3[è¯†åˆ«ç¼ºå¤±ä¿¡æ¯]
    end

    C[RAG ç³»ç»Ÿ] --> D{è¯„ä¼°ç›®æ ‡}
    D -->|æ£€ç´¢æ’åº| A1
    D -->|å†…å®¹ä½¿ç”¨| B1

    style A1 fill:#FFE4B5
    style B1 fill:#98FB98
```

**Context Precision ç¤ºä¾‹**ï¼š

```typescript
import { createContextPrecisionScorer } from '@mastra/evals/scorers/llm';

const contextPrecisionScorer = createContextPrecisionScorer({
  model: openai('gpt-4o-mini'),
  // åŠ¨æ€æå–ä¸Šä¸‹æ–‡ï¼ˆé€‚ç”¨äº RAG ç³»ç»Ÿï¼‰
  extractContext: async ({ run }) => {
    // ä» RAG ç³»ç»Ÿä¸­æå–æ£€ç´¢åˆ°çš„æ–‡æ¡£
    const documents = await vectorStore.search(run.input.query);
    return documents.map((doc) => doc.content);
  },
});

// è¯„ä¼°æ£€ç´¢è´¨é‡
const result = await contextPrecisionScorer.run({
  input: { query: 'Next.js çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ' },
  output: { answer: 'Next.js æä¾› SSRã€ISR...' },
});
```

**Context Relevance ç¤ºä¾‹**ï¼š

```typescript
import { createContextRelevanceScorer } from '@mastra/evals/scorers/llm';

const contextRelevanceScorer = createContextRelevanceScorer({
  model: openai('gpt-4o-mini'),
  context: ['Next.js æ”¯æŒæœåŠ¡ç«¯æ¸²æŸ“', 'React æ˜¯å‰ç«¯æ¡†æ¶', 'Python æ˜¯åç«¯è¯­è¨€'],
});

const result = await contextRelevanceScorer.run({
  input: 'Next.js çš„ç‰¹æ€§æ˜¯ä»€ä¹ˆï¼Ÿ',
  output: 'Next.js æ”¯æŒæœåŠ¡ç«¯æ¸²æŸ“ï¼Œæå‡ SEO...',
});

// result.reason ä¼šæ˜¾ç¤ºï¼š
// - ä½¿ç”¨äº†ç¬¬ 1 æ¡ä¸Šä¸‹æ–‡ (Next.js SSR)
// - ç¬¬ 2 æ¡éƒ¨åˆ†ç›¸å…³
// - ç¬¬ 3 æ¡ä¸ç›¸å…³
```

### 3. è¾“å‡ºè´¨é‡ Scorers

#### Toxicity

æ£€æµ‹æœ‰å®³æˆ–ä¸å½“å†…å®¹ã€‚

```typescript
import { createToxicityScorer } from '@mastra/evals/scorers/llm';

const toxicityScorer = createToxicityScorer({
  model: openai('gpt-4o-mini'),
});

// å®‰å…¨å†…å®¹
const safe = await toxicityScorer.run({
  input: 'ä½ å¥½',
  output: 'æ‚¨å¥½ï¼æˆ‘èƒ½ä¸ºæ‚¨æä¾›ä»€ä¹ˆå¸®åŠ©ï¼Ÿ',
});
console.log(safe.score); // 0.0 (æ— æ¯’æ€§)

// æœ‰å®³å†…å®¹
const toxic = await toxicityScorer.run({
  input: 'å¸®æˆ‘å†™é‚®ä»¶',
  output: 'ä½ è¿™ä¸ªç¬¨è›‹...',
});
console.log(toxic.score); // æ¥è¿‘ 1.0 (æ£€æµ‹åˆ°æ¯’æ€§)
```

#### Bias

æ£€æµ‹æ½œåœ¨åè§ã€‚

```typescript
import { createBiasScorer } from '@mastra/evals/scorers/llm';

const biasScorer = createBiasScorer({
  model: openai('gpt-4o-mini'),
  scale: 1, // 0-1 åˆ†æ•°èŒƒå›´
});

const result = await biasScorer.run({
  input: 'æè¿°ç¨‹åºå‘˜',
  output: 'ç¨‹åºå‘˜é€šå¸¸æ˜¯ç”·æ€§ï¼Œæ“…é•¿æ•°å­¦...',
});

// result ä¼šè¯†åˆ«æ€§åˆ«åˆ»æ¿å°è±¡
console.log(result.score); // åè§ç¨‹åº¦åˆ†æ•°
console.log(result.reason); // "æ£€æµ‹åˆ°æ€§åˆ«åˆ»æ¿å°è±¡..."
```

### å†…ç½® Scorers é€ŸæŸ¥è¡¨

| Scorer                 | åˆ†æ•°èŒƒå›´ | è¶Šé«˜è¶Šå¥½? | ä¸»è¦ç”¨é€”       |
| ---------------------- | -------- | --------- | -------------- |
| **Answer Relevancy**   | 0-1      | âœ…        | å›ç­”æ˜¯å¦åˆ‡é¢˜   |
| **Answer Similarity**  | 0-1      | âœ…        | CI/CD å›å½’æµ‹è¯• |
| **Faithfulness**       | 0-1      | âœ…        | RAG äº‹å®å‡†ç¡®æ€§ |
| **Hallucination**      | 0-1      | âŒ        | æ£€æµ‹è™šå‡ä¿¡æ¯   |
| **Completeness**       | 0-1      | âœ…        | ä¿¡æ¯å®Œæ•´æ€§     |
| **Context Precision**  | 0-1      | âœ…        | æ£€ç´¢æ’åºè´¨é‡   |
| **Context Relevance**  | 0-1      | âœ…        | ä¸Šä¸‹æ–‡ç›¸å…³æ€§   |
| **Toxicity**           | 0-1      | âŒ        | å†…å®¹å®‰å…¨       |
| **Bias**               | 0-1      | âŒ        | åè§æ£€æµ‹       |
| **Tone Consistency**   | 0-1      | âœ…        | é£æ ¼ä¸€è‡´æ€§     |
| **Tool Call Accuracy** | 0-1      | âœ…        | å·¥å…·é€‰æ‹©æ­£ç¡®æ€§ |
| **Prompt Alignment**   | 0-1      | âœ…        | å¯¹é½ç”¨æˆ·æ„å›¾   |

---

## è‡ªå®šä¹‰ Scorers

### åŸºç¡€ç»“æ„

```typescript
import { createScorer } from '@mastra/core/scorers';
import { z } from 'zod';

const customScorer = createScorer({
  name: 'My Custom Scorer',
  description: 'è¯„ä¼°ç‰¹å®šä¸šåŠ¡é€»è¾‘',

  // å¯é€‰ï¼šLLM é…ç½®
  judge: {
    model: openai('gpt-4o-mini'),
    instructions: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯„ä¼°è€…...',
  },
})
  .preprocess(/* æ­¥éª¤ 1 */)
  .analyze(/* æ­¥éª¤ 2 */)
  .generateScore(/* æ­¥éª¤ 3 - å¿…éœ€ */)
  .generateReason(/* æ­¥éª¤ 4 */)
  .build();
```

### æ–¹å¼ 1: ä½¿ç”¨å‡½æ•° (ç¡®å®šæ€§é€»è¾‘)

```typescript
const lengthScorer = createScorer({
  name: 'Response Length Scorer',
  description: 'è¯„ä¼°å›ç­”é•¿åº¦æ˜¯å¦åˆé€‚',
})
  .preprocess(({ run }) => {
    // æå–å’Œæ¸…æ´—æ•°æ®
    const text = run.output.text || run.output;
    const wordCount = text.split(/\s+/).length;
    const charCount = text.length;

    return {
      wordCount,
      charCount,
      hasEmptyResponse: wordCount === 0,
    };
  })
  .generateScore(({ results }) => {
    const { wordCount, hasEmptyResponse } = results.preprocessStepResult;

    // ä¸šåŠ¡è§„åˆ™
    if (hasEmptyResponse) return 0.0;
    if (wordCount < 10) return 0.3;
    if (wordCount < 50) return 0.7;
    if (wordCount < 200) return 1.0;
    if (wordCount < 500) return 0.8;
    return 0.5; // å¤ªé•¿äº†
  })
  .generateReason(({ score, results }) => {
    const { wordCount } = results.preprocessStepResult;

    if (score === 1.0) {
      return `å®Œç¾é•¿åº¦ï¼š${wordCount} è¯ï¼Œè¯¦ç»†ä¸”ç®€æ´`;
    }
    if (score < 0.5) {
      return `å¤ª${wordCount < 50 ? 'çŸ­' : 'é•¿'}ï¼š${wordCount} è¯`;
    }
    return `å¯æ¥å—é•¿åº¦ï¼š${wordCount} è¯`;
  })
  .build();
```

### æ–¹å¼ 2: ä½¿ç”¨ Prompt Objects (LLM è¯„ä¼°)

```typescript
const glutenCheckerScorer = createScorer({
  name: 'Gluten Checker',
  description: 'æ£€æŸ¥é£Ÿè°±æ˜¯å¦å«éº¸è´¨',
  judge: {
    model: openai('gpt-4o'),
    instructions: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¨å¸ˆï¼Œè¯†åˆ«é£Ÿè°±ä¸­çš„éº¸è´¨æˆåˆ†',
  },
})
  .analyze({
    description: 'è¯†åˆ«éº¸è´¨æ¥æº',
    outputSchema: z.object({
      isGlutenFree: z.boolean(),
      glutenSources: z.array(z.string()),
      reasoning: z.string(),
    }),
    createPrompt: ({ run }) => `
      æ£€æŸ¥è¿™ä¸ªé£Ÿè°±æ˜¯å¦å«éº¸è´¨ï¼š
      
      ${run.output}
      
      æ£€æŸ¥ä»¥ä¸‹æˆåˆ†ï¼š
      - å°éº¦ (wheat)
      - å¤§éº¦ (barley)
      - é»‘éº¦ (rye)
      - å¸¸è§æ¥æºï¼šé¢ç²‰ã€é¢é£Ÿã€é¢åŒ…
      
      è¿”å› JSON æ ¼å¼ï¼š
      {
        "isGlutenFree": boolean,
        "glutenSources": ["æˆåˆ†åˆ—è¡¨"],
        "reasoning": "åˆ†æè¯´æ˜"
      }
    `,
  })
  .generateScore(({ results }) => {
    const analysis = results.analyzeStepResult;
    return analysis.isGlutenFree ? 1.0 : 0.0;
  })
  .generateReason(({ results }) => {
    const analysis = results.analyzeStepResult;

    if (analysis.isGlutenFree) {
      return 'âœ… æ­¤é£Ÿè°±ä¸å«éº¸è´¨';
    }

    return `âŒ æ£€æµ‹åˆ°éº¸è´¨ï¼š${analysis.glutenSources.join(', ')}ã€‚${analysis.reasoning}`;
  })
  .build();
```

### æ–¹å¼ 3: æ··åˆæ¨¡å¼ (å‡½æ•° + LLM)

````typescript
const hybridScorer = createScorer({
  name: 'Hybrid Quality Scorer',
  description: 'ç»“åˆè§„åˆ™å’Œ LLM è¯„ä¼°',
  judge: {
    model: openai('gpt-4o-mini'),
    instructions: 'è¯„ä¼°å†…å®¹è´¨é‡',
  },
})
  // å‡½æ•°ï¼šæå–ç»Ÿè®¡æ•°æ®
  .preprocess(({ run }) => {
    const text = run.output;
    return {
      wordCount: text.split(/\s+/).length,
      hasLinks: /https?:\/\//.test(text),
      hasCode: /```/.test(text),
      sentenceCount: text.split(/[.!?]+/).length,
    };
  })
  // LLMï¼šåˆ†æè¯­ä¹‰è´¨é‡
  .analyze({
    description: 'è¯„ä¼°è¯­ä¹‰è´¨é‡',
    outputSchema: z.object({
      clarity: z.number().min(0).max(1),
      coherence: z.number().min(0).max(1),
      informativeness: z.number().min(0).max(1),
    }),
    createPrompt: ({ run }) => `
      è¯„ä¼°è¿™æ®µæ–‡æœ¬çš„è´¨é‡ï¼ˆ0-1ï¼‰ï¼š
      
      ${run.output}
      
      è¯„ä¼°ç»´åº¦ï¼š
      - clarity: è¡¨è¾¾æ¸…æ™°åº¦
      - coherence: é€»è¾‘è¿è´¯æ€§
      - informativeness: ä¿¡æ¯é‡
      
      è¿”å› JSON æ ¼å¼ã€‚
    `,
  })
  // å‡½æ•°ï¼šç»¼åˆè®¡ç®—åˆ†æ•°
  .generateScore(({ results }) => {
    const stats = results.preprocessStepResult;
    const quality = results.analyzeStepResult;

    // åŸºç¡€åˆ†ï¼šé•¿åº¦åˆç†æ€§
    let baseScore = stats.wordCount >= 20 && stats.wordCount <= 500 ? 0.3 : 0.0;

    // è¯­ä¹‰åˆ†ï¼šLLM è¯„ä¼°çš„å¹³å‡å€¼
    const semanticScore =
      ((quality.clarity + quality.coherence + quality.informativeness) / 3) * 0.7;

    return baseScore + semanticScore;
  })
  .generateReason(({ score, results }) => {
    const stats = results.preprocessStepResult;
    const quality = results.analyzeStepResult;

    return `
      ç»¼åˆè¯„åˆ†ï¼š${(score * 100).toFixed(1)}%
      
      ç»Ÿè®¡ä¿¡æ¯ï¼š
      - å­—æ•°ï¼š${stats.wordCount}
      - å¥å­æ•°ï¼š${stats.sentenceCount}
      - åŒ…å«é“¾æ¥ï¼š${stats.hasLinks ? 'æ˜¯' : 'å¦'}
      
      è´¨é‡åˆ†æï¼š
      - æ¸…æ™°åº¦ï¼š${(quality.clarity * 100).toFixed(0)}%
      - è¿è´¯æ€§ï¼š${(quality.coherence * 100).toFixed(0)}%
      - ä¿¡æ¯é‡ï¼š${(quality.informativeness * 100).toFixed(0)}%
    `.trim();
  })
  .build();
````

### Agent ç±»å‹çš„ Scorer

```typescript
// è‡ªåŠ¨ç±»å‹æ¨å¯¼
const agentScorer = createScorer({
  name: 'Agent Response Quality',
  description: 'è¯„ä¼° Agent å“åº”è´¨é‡',
  type: 'agent', // è‡ªåŠ¨æä¾› Agent è¾“å…¥/è¾“å‡ºç±»å‹
})
  .preprocess(({ run }) => {
    // run.input è‡ªåŠ¨ç±»å‹åŒ–ä¸º ScorerRunInputForAgent
    const userMessages = run.input.inputMessages;
    const lastMessage = userMessages[userMessages.length - 1];

    return {
      userQuery: lastMessage?.content || '',
      messageCount: userMessages.length,
    };
  })
  .generateScore(({ run, results }) => {
    // run.output è‡ªåŠ¨ç±»å‹åŒ–ä¸º ScorerRunOutputForAgent
    const response = run.output[0]?.content || '';
    const { userQuery } = results.preprocessStepResult;

    // ç®€å•çš„ç›¸å…³æ€§æ£€æŸ¥
    const queryWords = userQuery.toLowerCase().split(/\s+/);
    const responseWords = response.toLowerCase().split(/\s+/);
    const matchCount = queryWords.filter((w) => responseWords.includes(w)).length;

    return Math.min(matchCount / queryWords.length, 1.0);
  })
  .build();
```

---

## Live è¯„ä¼°

### æ¦‚å¿µå’Œæ¶æ„

```mermaid
sequenceDiagram
    participant User
    participant Agent
    participant Scorer
    participant Storage

    User->>Agent: å‘é€è¯·æ±‚
    Agent->>Agent: å¤„ç†è¯·æ±‚
    Agent-->>User: è¿”å›å“åº” (ç«‹å³)

    par å¼‚æ­¥è¯„ä¼°
        Agent->>Scorer: è§¦å‘è¯„ä¼° (éé˜»å¡)
        Scorer->>Scorer: æ‰§è¡Œè¯„ä¼°é€»è¾‘
        Scorer->>Storage: ä¿å­˜ç»“æœ
    end

    Note over Agent,Scorer: ç”¨æˆ·ä½“éªŒä¸å—å½±å“
```

**æ ¸å¿ƒç‰¹ç‚¹**ï¼š

- âœ… **å¼‚æ­¥æ‰§è¡Œ**ï¼šä¸é˜»å¡ Agent å“åº”
- âœ… **é‡‡æ ·æ§åˆ¶**ï¼šé€šè¿‡ `rate` æ§åˆ¶è¯„ä¼°é¢‘ç‡
- âœ… **è‡ªåŠ¨å­˜å‚¨**ï¼šç»“æœå­˜å…¥ `mastra_scorers` è¡¨

### ä¸º Agent æ·»åŠ  Scorers

```typescript
import { Agent } from '@mastra/core/agent';
import { openai } from '@ai-sdk/openai';
import {
  createAnswerRelevancyScorer,
  createToxicityScorer,
  createCompletenessScorer,
} from '@mastra/evals/scorers/llm';

export const evaluatedAgent = new Agent({
  name: 'customer-support',
  instructions: 'ä½ æ˜¯ä¸€ä¸ªå®¢æœåŠ©æ‰‹...',
  model: openai('gpt-4o-mini'),

  scorers: {
    // è¯„ä¼°å›ç­”ç›¸å…³æ€§ (50% é‡‡æ ·ç‡)
    relevancy: {
      scorer: createAnswerRelevancyScorer({
        model: openai('gpt-4o-mini'),
      }),
      sampling: {
        type: 'ratio',
        rate: 0.5, // åªè¯„ä¼° 50% çš„å“åº”
      },
    },

    // è¯„ä¼°å†…å®¹å®‰å…¨ (100% é‡‡æ ·ç‡)
    safety: {
      scorer: createToxicityScorer({
        model: openai('gpt-4o-mini'),
      }),
      sampling: {
        type: 'ratio',
        rate: 1.0, // è¯„ä¼°æ‰€æœ‰å“åº”
      },
    },

    // è¯„ä¼°å›ç­”å®Œæ•´æ€§ (10% é‡‡æ ·ç‡)
    completeness: {
      scorer: createCompletenessScorer({
        model: openai('gpt-4o-mini'),
      }),
      sampling: {
        type: 'ratio',
        rate: 0.1, // è¯„ä¼° 10% çš„å“åº”
      },
    },
  },
});
```

### ä¸º Workflow Steps æ·»åŠ  Scorers

```typescript
import { createWorkflow, createStep } from '@mastra/core/workflows';
import { z } from 'zod';
import { customStepScorer } from '../scorers/custom-step-scorer';

const contentGenerationStep = createStep({
  id: 'generate-content',
  inputSchema: z.object({
    topic: z.string(),
  }),
  outputSchema: z.object({
    content: z.string(),
  }),
  execute: async ({ inputData, mastra }) => {
    const agent = mastra.getAgent('contentAgent');
    const response = await agent.generate(`å†™ä¸€ç¯‡å…³äº ${inputData.topic} çš„æ–‡ç« `);

    return {
      content: response.text,
    };
  },

  // ä¸ºæ­¤æ­¥éª¤æ·»åŠ  Scorer
  scorers: {
    quality: {
      scorer: customStepScorer(),
      sampling: {
        type: 'ratio',
        rate: 1.0, // è¯„ä¼°æ¯æ¬¡æ‰§è¡Œ
      },
    },
  },
});

export const contentWorkflow = createWorkflow({
  id: 'content-generation',
  inputSchema: z.object({
    topic: z.string(),
  }),
  outputSchema: z.object({
    content: z.string(),
  }),
})
  .then(contentGenerationStep)
  .commit();
```

### é‡‡æ ·ç­–ç•¥

```mermaid
graph LR
    A[Sampling Rate] --> B{rate = ?}

    B -->|1.0| C[100%<br/>æ‰€æœ‰å“åº”]
    B -->|0.5| D[50%<br/>ä¸€åŠå“åº”]
    B -->|0.1| E[10%<br/>ååˆ†ä¹‹ä¸€]
    B -->|0.0| F[0%<br/>ç¦ç”¨è¯„ä¼°]

    C --> G[é€‚ç”¨: å®‰å…¨æ£€æŸ¥]
    D --> H[é€‚ç”¨: è´¨é‡ç›‘æ§]
    E --> I[é€‚ç”¨: æˆæœ¬æ§åˆ¶]
    F --> J[é€‚ç”¨: è°ƒè¯•é˜¶æ®µ]

    style C fill:#FFB6C1
    style D fill:#FFD700
    style E fill:#98FB98
    style F fill:#D3D3D3
```

**é‡‡æ ·ç‡é€‰æ‹©å»ºè®®**ï¼š

| Rate        | æˆæœ¬ | è¦†ç›–ç‡ | é€‚ç”¨åœºæ™¯             |
| ----------- | ---- | ------ | -------------------- |
| **1.0**     | é«˜   | 100%   | å®‰å…¨æ£€æŸ¥ã€åˆè§„å®¡è®¡   |
| **0.5**     | ä¸­   | 50%    | è´¨é‡ç›‘æ§ã€A/B æµ‹è¯•   |
| **0.1-0.2** | ä½   | 10-20% | è¶‹åŠ¿åˆ†æã€æˆæœ¬æ•æ„Ÿ   |
| **0.01**    | æä½ | 1%     | å¤§è§„æ¨¡æŠ½æ ·ã€åˆæ­¥è¯Šæ–­ |

---

## Trace è¯„ä¼°

### æ¶æ„å›¾

```mermaid
graph TB
    subgraph "å®æ—¶æ‰§è¡Œ"
        A[Agent è¿è¡Œ]
        B[ç”Ÿæˆ Trace]
        C[(Trace å­˜å‚¨)]
    end

    subgraph "æ‰¹é‡è¯„ä¼°"
        D[æ³¨å†Œ Scorers]
        E[Mastra Playground]
        F[é€‰æ‹© Traces]
        G[è¿è¡Œ Scorers]
        H[(è¯„åˆ†ç»“æœ)]
    end

    A --> B
    B --> C
    C --> F
    D --> E
    E --> F
    F --> G
    G --> H

    style C fill:#87CEEB
    style H fill:#FFD700
```

### é…ç½® Observability

```typescript
import { Mastra } from '@mastra/core/mastra';
import { LibSQLStore } from '@mastra/core/storage';

const mastra = new Mastra({
  // é…ç½®å­˜å‚¨ä»¥æ”¶é›† Traces
  storage: new LibSQLStore({
    url: process.env.DATABASE_URL,
  }),

  // å¯ç”¨å¯è§‚æµ‹æ€§
  observability: {
    enabled: true,
  },

  // æ³¨å†Œ Scorers ç”¨äº Trace è¯„ä¼°
  scorers: {
    answerRelevancy: createAnswerRelevancyScorer({
      model: openai('gpt-4o-mini'),
    }),
    responseQuality: customQualityScorer,
  },

  agents: {
    customerSupport: evaluatedAgent,
  },
});
```

### åœ¨ Playground ä¸­è¯„ä¼° Traces

```bash
# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev

# è®¿é—® Playground
# http://localhost:4111
```

**æ“ä½œæ­¥éª¤**ï¼š

```mermaid
graph LR
    A[1. è¿›å…¥ Observability] --> B[2. é€‰æ‹© Traces]
    B --> C[3. é€‰æ‹© Scorer]
    C --> D[4. è¿è¡Œè¯„ä¼°]
    D --> E[5. æŸ¥çœ‹ç»“æœ]

    style A fill:#FFE4B5
    style E fill:#90EE90
```

1. **Observability é¢æ¿**ï¼šæŸ¥çœ‹æ‰€æœ‰å†å² Traces
2. **é€‰æ‹© Traces**ï¼šé€‰æ‹©è¦è¯„ä¼°çš„å¯¹è¯è®°å½•
3. **é€‰æ‹© Scorer**ï¼šä»å·²æ³¨å†Œçš„ Scorers ä¸­é€‰æ‹©
4. **æ‰¹é‡è¯„ä¼°**ï¼šå¯¹å¤šä¸ª Traces è¿è¡Œè¯„ä¼°
5. **ç»“æœåˆ†æ**ï¼šæŸ¥çœ‹åˆ†æ•°ã€åŸå› å’Œè¶‹åŠ¿

### ç¨‹åºåŒ–è¯„ä¼° Traces

```typescript
// è·å–å†å² Traces
const traces = await mastra.getTraces({
  agentId: 'customerSupport',
  startDate: new Date('2024-01-01'),
  endDate: new Date('2024-01-31'),
});

// å¯¹æ¯ä¸ª Trace è¿è¡Œ Scorer
for (const trace of traces) {
  const scorer = mastra.getScorer('answerRelevancy');

  const result = await scorer.run({
    input: trace.input,
    output: trace.output,
    runId: trace.id,
  });

  console.log(`Trace ${trace.id}: ${result.score}`);

  // ç»“æœè‡ªåŠ¨å­˜å‚¨åˆ° mastra_scorers è¡¨
}
```

---

## æœ€ä½³å®è·µ

### 1. Scorer è®¾è®¡åŸåˆ™

```mermaid
graph TB
    A[è®¾è®¡ Scorer] --> B[å•ä¸€èŒè´£]
    A --> C[å¯ç»„åˆæ€§]
    A --> D[å¯è§£é‡Šæ€§]

    B --> B1[ä¸€ä¸ª Scorer<br/>è¯„ä¼°ä¸€ä¸ªç»´åº¦]
    C --> C1[å¤šä¸ª Scorers<br/>ç»„åˆè¯„ä¼°]
    D --> D1[æä¾›æ¸…æ™°çš„<br/>generateReason]

    style B1 fill:#FFE4B5
    style C1 fill:#98FB98
    style D1 fill:#87CEEB
```

**âœ… å¥½çš„è®¾è®¡**ï¼š

```typescript
// å•ä¸€èŒè´£ï¼šåªæ£€æŸ¥é•¿åº¦
const lengthScorer = createScorer({...})
  .generateScore(({ run }) => {
    const wordCount = run.output.split(/\s+/).length;
    return wordCount >= 50 && wordCount <= 200 ? 1.0 : 0.5;
  });

// å•ä¸€èŒè´£ï¼šåªæ£€æŸ¥è¯­æ°”
const toneScorer = createToneConsistencyScorer({...});

// ç»„åˆä½¿ç”¨
const agent = new Agent({
  scorers: {
    length: { scorer: lengthScorer, sampling: { rate: 1 } },
    tone: { scorer: toneScorer, sampling: { rate: 0.5 } },
  },
});
```

**âŒ é¿å…çš„è®¾è®¡**ï¼š

```typescript
// èŒè´£è¿‡å¤šï¼šæ··åˆäº†å¤šä¸ªè¯„ä¼°ç»´åº¦
const everythingScorer = createScorer({...})
  .generateScore(({ run }) => {
    // æ£€æŸ¥é•¿åº¦ã€è¯­æ°”ã€æ¯’æ€§ã€ç›¸å…³æ€§... å¤ªå¤šäº†ï¼
    return complexCalculation();
  });
```

### 2. é‡‡æ ·ç­–ç•¥

```typescript
// åˆ†å±‚é‡‡æ ·
const agent = new Agent({
  scorers: {
    // é«˜ä¼˜å…ˆçº§ï¼š100% é‡‡æ ·
    safety: {
      scorer: toxicityScorer,
      sampling: { type: 'ratio', rate: 1.0 },
    },

    // ä¸­ä¼˜å…ˆçº§ï¼š50% é‡‡æ ·
    quality: {
      scorer: relevancyScorer,
      sampling: { type: 'ratio', rate: 0.5 },
    },

    // ä½ä¼˜å…ˆçº§ï¼š10% é‡‡æ ·
    style: {
      scorer: toneScorer,
      sampling: { type: 'ratio', rate: 0.1 },
    },
  },
});
```

### 3. é”™è¯¯å¤„ç†

```typescript
const robustScorer = createScorer({
  name: 'Robust Scorer',
  description: 'å…·æœ‰é”™è¯¯å¤„ç†çš„ Scorer',
})
  .preprocess(({ run }) => {
    try {
      const text = run.output?.text || run.output || '';
      return {
        text,
        wordCount: text.split(/\s+/).length,
      };
    } catch (error) {
      console.error('Preprocess error:', error);
      return {
        text: '',
        wordCount: 0,
        error: error.message,
      };
    }
  })
  .generateScore(({ results }) => {
    const { wordCount, error } = results.preprocessStepResult;

    // å¦‚æœé¢„å¤„ç†å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†æ•°
    if (error) {
      return 0.0;
    }

    return wordCount > 10 ? 1.0 : 0.5;
  })
  .generateReason(({ score, results }) => {
    const { error } = results.preprocessStepResult;

    if (error) {
      return `âš ï¸ è¯„ä¼°å¤±è´¥: ${error}`;
    }

    return `è¯„åˆ†: ${score}`;
  })
  .build();
```

### 4. æ€§èƒ½ä¼˜åŒ–

```typescript
// ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹è¿›è¡Œé‡‡æ ·è¯„ä¼°
const costEffectiveScorer = createAnswerRelevancyScorer({
  model: openai('gpt-4o-mini'), // è€Œä¸æ˜¯ gpt-4o
});

// ç¼“å­˜é¢„å¤„ç†ç»“æœ
const cachedPreprocess = (() => {
  const cache = new Map();

  return ({ run }) => {
    const key = JSON.stringify(run.output);

    if (cache.has(key)) {
      return cache.get(key);
    }

    const result = expensiveProcessing(run.output);
    cache.set(key, result);
    return result;
  };
})();

const efficientScorer = createScorer({...})
  .preprocess(cachedPreprocess)
  .generateScore({...});
```

### 5. ç›‘æ§å’Œå‘Šè­¦

```typescript
// è®¾ç½®åˆ†æ•°é˜ˆå€¼å‘Šè­¦
const monitoredAgent = new Agent({
  scorers: {
    safety: {
      scorer: toxicityScorer,
      sampling: { type: 'ratio', rate: 1.0 },
    },
  },

  // ç›‘å¬è¯„åˆ†ç»“æœ
  onScore: async (scorerName, result) => {
    if (scorerName === 'safety' && result.score > 0.7) {
      // å‘é€å‘Šè­¦
      await sendAlert({
        level: 'critical',
        message: `æ£€æµ‹åˆ°é«˜æ¯’æ€§å“åº”: ${result.score}`,
        details: result.reason,
      });
    }
  },
});
```

### 6. æ•°æ®åˆ†æ

```typescript
// æŸ¥è¯¢è¯„åˆ†è¶‹åŠ¿
async function analyzeScoreTrends() {
  const scores = await db.query(`
    SELECT 
      scorer_name,
      DATE(created_at) as date,
      AVG(score) as avg_score,
      MIN(score) as min_score,
      MAX(score) as max_score,
      COUNT(*) as count
    FROM mastra_scorers
    WHERE agent_id = 'customer-support'
      AND created_at >= DATE('now', '-30 days')
    GROUP BY scorer_name, DATE(created_at)
    ORDER BY date DESC
  `);

  return scores;
}

// è¯†åˆ«é—®é¢˜æ¨¡å¼
async function findLowScores() {
  const lowScores = await db.query(`
    SELECT 
      run_id,
      scorer_name,
      score,
      reason,
      created_at
    FROM mastra_scorers
    WHERE score < 0.5
    ORDER BY created_at DESC
    LIMIT 50
  `);

  return lowScores;
}
```

---

## ä¸ä¼ ç»Ÿ Evals å¯¹æ¯”

### Scorers vs æ—§ Evals API

```mermaid
graph LR
    subgraph "æ—§ Evals API"
        A1[Metric Class]
        A2[Judge Class]
        A3[measure()]
    end

    subgraph "æ–° Scorers API"
        B1[createScorer]
        B2[Pipeline Steps]
        B3[.run()]
    end

    A1 --> C[è¿ç§»]
    A2 --> C
    A3 --> C

    C --> B1
    C --> B2
    C --> B3

    style B1 fill:#90EE90
    style B2 fill:#90EE90
    style B3 fill:#90EE90
```

### å¯¹æ¯”è¡¨

| ç‰¹æ€§         | æ—§ Evals API | æ–° Scorers API   |
| ------------ | ------------ | ---------------- |
| **API è®¾è®¡** | åŸºäºç±»ç»§æ‰¿   | å‡½æ•°å¼ Pipeline  |
| **çµæ´»æ€§**   | å›ºå®šç»“æ„     | æ¨¡å—åŒ–æ­¥éª¤       |
| **ç±»å‹å®‰å…¨** | æ‰‹åŠ¨å®šä¹‰     | Zod + TypeScript |
| **å…ƒæ•°æ®**   | åŸºç¡€         | ä¸°å¯Œï¼ˆæ¯æ­¥ç»“æœï¼‰ |
| **é”™è¯¯åˆ†æ** | æœ‰é™         | è¯¦ç»†è¿½è¸ª         |
| **æ•°æ®ç»“æ„** | é™åˆ¶æ€§       | çµæ´»è¯„ä¼°         |
| **åº•å±‚å®ç°** | è‡ªå®šä¹‰       | åŸºäº Workflows   |

### è¿ç§»ç¤ºä¾‹

**æ—§ API**ï¼š

```typescript
import { Metric, MastraAgentJudge } from '@mastra/evals';

class WorldCountryMetric extends Metric {
  constructor(model) {
    const judge = new MastraAgentJudge({
      model,
      instructions: 'è¯†åˆ«çœŸå®çš„å›½å®¶',
      promptTemplate: (query, response) => `...`,
      outputSchema: z.object({...}),
    });

    super({ name: 'world-countries', judge });
  }

  async measure(query, response) {
    const result = await this.judge.judge(query, response);
    return {
      score: result.score,
      info: { ... },
    };
  }
}
```

**æ–° API**ï¼š

```typescript
import { createScorer } from '@mastra/core/scorers';

const worldCountryScorer = createScorer({
  name: 'World Countries',
  description: 'è¯†åˆ«çœŸå®çš„å›½å®¶',
  judge: {
    model: openai('gpt-4o-mini'),
    instructions: 'è¯†åˆ«çœŸå®çš„å›½å®¶',
  },
})
  .analyze({
    description: 'åˆ†æå›½å®¶',
    outputSchema: z.object({
      validCountries: z.array(z.string()),
      invalidItems: z.array(z.string()),
    }),
    createPrompt: ({ run }) => `
      åˆ†æè¿™ä¸ªå›ç­”ä¸­çš„å›½å®¶ï¼š
      
      é—®é¢˜ï¼š${run.input}
      å›ç­”ï¼š${run.output}
      
      è¯†åˆ«ï¼š
      1. çœŸå®å›½å®¶
      2. è™šå‡/é”™è¯¯é¡¹
    `,
  })
  .generateScore(({ results }) => {
    const { validCountries, invalidItems } = results.analyzeStepResult;
    const total = validCountries.length + invalidItems.length;
    return total > 0 ? validCountries.length / total : 0;
  })
  .generateReason(({ results }) => {
    const { validCountries, invalidItems } = results.analyzeStepResult;

    if (invalidItems.length === 0) {
      return 'âœ… æ‰€æœ‰é¡¹ç›®éƒ½æ˜¯çœŸå®å›½å®¶';
    }

    return `
      çœŸå®å›½å®¶ï¼š${validCountries.join(', ')}
      é”™è¯¯é¡¹ï¼š${invalidItems.join(', ')}
    `;
  })
  .build();
```

**è¿ç§»æ­¥éª¤**ï¼š

1. ç”¨ `createScorer` æ›¿æ¢ç±»ç»§æ‰¿
2. å°† `judge` é€»è¾‘æ‹†åˆ†ä¸º Pipeline æ­¥éª¤
3. ç”¨ `analyze` + `generateScore` æ›¿æ¢ `measure`
4. æ·»åŠ  `generateReason` æä¾›è§£é‡Š

---

## æ€»ç»“

### Scorers æ ¸å¿ƒä»·å€¼

```mermaid
mindmap
  root((Scorers))
    è‡ªåŠ¨åŒ–
      å¼‚æ­¥è¯„ä¼°
      é‡‡æ ·æ§åˆ¶
      æŒä¹…åŒ–å­˜å‚¨
    å¯é æ€§
      ç±»å‹å®‰å…¨
      é”™è¯¯å¤„ç†
      æ•°æ®è¿½è¸ª
    çµæ´»æ€§
      æ¨¡å—åŒ–è®¾è®¡
      æ··åˆè¯„ä¼°
      è‡ªå®šä¹‰æ‰©å±•
    å¯è§‚æµ‹æ€§
      å®æ—¶ç›‘æ§
      è¶‹åŠ¿åˆ†æ
      è°ƒè¯•æ”¯æŒ
```

### ä½¿ç”¨åœºæ™¯çŸ©é˜µ

| åœºæ™¯         | æ¨è Scorers                          | é‡‡æ ·ç‡ | ä¼˜å…ˆçº§ |
| ------------ | ------------------------------------- | ------ | ------ |
| **ç”Ÿäº§ç¯å¢ƒ** | Toxicity, Hallucination               | 1.0    | ğŸ”´ é«˜  |
| **è´¨é‡ç›‘æ§** | Answer Relevancy, Completeness        | 0.5    | ğŸŸ¡ ä¸­  |
| **æ€§èƒ½ä¼˜åŒ–** | Context Precision, Tool Call Accuracy | 0.1    | ğŸŸ¢ ä½  |
| **A/B æµ‹è¯•** | Custom Scorers                        | 0.5    | ğŸŸ¡ ä¸­  |
| **è°ƒè¯•å¼€å‘** | All Scorers                           | 1.0    | ğŸ”´ é«˜  |

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…åŒ…
npm install @mastra/evals@latest

# 2. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev

# 3. è®¿é—® Playground
# http://localhost:4111

# 4. æŸ¥çœ‹ Scorers é¢æ¿
```

### ä¸‹ä¸€æ­¥

1. **æ¢ç´¢å†…ç½® Scorers**ï¼šä»å¸¸è§è¯„ä¼°åœºæ™¯å¼€å§‹
2. **åˆ›å»ºè‡ªå®šä¹‰ Scorer**ï¼šé’ˆå¯¹ä¸šåŠ¡é€»è¾‘å®šåˆ¶è¯„ä¼°
3. **é›†æˆåˆ° CI/CD**ï¼šå°†è¯„ä¼°åŠ å…¥è‡ªåŠ¨åŒ–æµ‹è¯•
4. **åˆ†æè¶‹åŠ¿æ•°æ®**ï¼šæŒç»­ä¼˜åŒ– AI ç³»ç»Ÿ

---

## å‚è€ƒèµ„æº

- **å®˜æ–¹æ–‡æ¡£**: https://mastra.ai/docs/scorers/overview
- **å†…ç½® Scorers**: https://mastra.ai/docs/scorers/off-the-shelf-scorers
- **è‡ªå®šä¹‰ Scorers**: https://mastra.ai/docs/scorers/custom-scorers
- **Playground**: https://mastra.ai/docs/getting-started/studio
- **ç¤ºä¾‹ä»£ç **: https://mastra.ai/docs/examples
