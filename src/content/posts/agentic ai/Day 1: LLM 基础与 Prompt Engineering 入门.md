---
title: 'Day 1: LLM åŸºç¡€ä¸ Prompt Engineering å…¥é—¨'
date: '2025-12-24'
excerpt: 'åœ¨ä¸€å¤©å†…å»ºç«‹å¯¹ LLM å·¥ä½œåŸç†ã€Prompt Engineering æ ¸å¿ƒæ¦‚å¿µä»¥åŠå¸¸è§æç¤ºæŠ€æœ¯çš„å·¥ç¨‹çº§ç†è§£ï¼Œå¹¶èƒ½å¤Ÿåœ¨å®é™…ä»»åŠ¡ä¸­æ­£ç¡®é€‰æ‹©ä¸åº”ç”¨ã€‚'
tags: ['Agentic AI']
series: 'Agentic AI'
---


# Day 1: LLM åŸºç¡€ä¸ Prompt Engineering å…¥é—¨

> **å­¦ä¹ ç›®æ ‡**  
> åœ¨ä¸€å¤©å†…å»ºç«‹å¯¹ LLM å·¥ä½œåŸç†ã€Prompt Engineering æ ¸å¿ƒæ¦‚å¿µä»¥åŠå¸¸è§æç¤ºæŠ€æœ¯çš„å·¥ç¨‹çº§ç†è§£ï¼Œå¹¶èƒ½å¤Ÿåœ¨å®é™…ä»»åŠ¡ä¸­æ­£ç¡®é€‰æ‹©ä¸åº”ç”¨ã€‚

---

## ğŸ“… å­¦ä¹ è®¡åˆ’æ¦‚è§ˆ

- **ä¸Šåˆä»»åŠ¡ (2å°æ—¶)**: LLM åŸºç¡€ç†è®ºä¸é…ç½®å‚æ•°
- **ä¸‹åˆä»»åŠ¡ (1.5å°æ—¶)**: æç¤ºæŠ€æœ¯å®è·µ
- **æ™šä¸Šä»»åŠ¡ (0.5å°æ—¶)**: æ€»ç»“ä¸åœºæ™¯æ˜ å°„

---

## ğŸŒ… ä¸Šåˆä»»åŠ¡ï¼šLLM åŸºç¡€ç†è®º

### 1. LLM çš„åŸºæœ¬å·¥ä½œåŸç†

#### 1.1 Transformer æ¶æ„æ¦‚è§ˆ

**æ ¸å¿ƒç†å¿µ**  
LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰é€šå¸¸åŸºäº **Transformer** æ¶æ„ï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºåºåˆ—æ•°æ®è®¾è®¡çš„æ·±åº¦å­¦ä¹ æ¶æ„ã€‚

**ä¸»è¦ç»„ä»¶**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Token Embedding Layer        â”‚  â† å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Multi-Head Self-Attention    â”‚  â† è®¡ç®— token é—´å…³ç³»
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Feed-Forward Network          â”‚  â† éçº¿æ€§å˜æ¢
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Layer Normalization           â”‚  â† ç¨³å®šè®­ç»ƒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ¶æ„ç‰¹ç‚¹**

| ç‰¹æ€§ | è¯´æ˜ | ä¼˜åŠ¿ |
|------|------|------|
| å¹¶è¡Œè®¡ç®— | ä¸ä¾èµ–é¡ºåºå¤„ç† | è®­ç»ƒé€Ÿåº¦å¿« |
| æ³¨æ„åŠ›æœºåˆ¶ | åŠ¨æ€å»ºæ¨¡ token å…³ç³» | é•¿è·ç¦»ä¾èµ–å»ºæ¨¡ |
| å¯æ‰©å±•æ€§ | æ”¯æŒå¤§è§„æ¨¡é¢„è®­ç»ƒ | æ¶Œç°èƒ½åŠ› |

> ğŸ’¡ **æ ¸å¿ƒæ´å¯Ÿ**  
> Transformer çš„é©å‘½æ€§åœ¨äºï¼š**é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å»ºæ¨¡ token ä¹‹é—´çš„å…³ç³»ï¼Œè€Œéé¡ºåºä¾èµ–**ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå¹¶è¡Œå¤„ç†å¹¶æ•è·é•¿è·ç¦»è¯­ä¹‰å…³è”ã€‚

---

#### 1.2 Tokenï¼šæœ€å°å¤„ç†å•å…ƒ

**ä»€ä¹ˆæ˜¯ Tokenï¼Ÿ**

LLM ä¸ç›´æ¥å¤„ç†"è¯"æˆ–"å¥å­"ï¼Œè€Œæ˜¯å°†æ–‡æœ¬åˆ†è§£ä¸º **token**ï¼ˆæœ€å°å¤„ç†å•å…ƒï¼‰ã€‚

**Token çš„ç±»å‹**

- **å­è¯ (Subword)**: `"playing"` â†’ `["play", "ing"]`
- **å­—ç¬¦ç‰‡æ®µ**: `"AI"` â†’ `["A", "I"]` æˆ– `["AI"]`
- **ç‰¹æ®Šç¬¦å·**: `<BOS>`, `<EOS>`, `<PAD>`

**å®é™…ç¤ºä¾‹**

```python
# ä½¿ç”¨ tiktoken (OpenAI çš„ tokenizer)
import tiktoken

encoder = tiktoken.get_encoding("cl100k_base")
text = "I love AI!"

tokens = encoder.encode(text)
print(tokens)  # [40, 3021, 15592, 0]

# è§£ç å›æ–‡æœ¬
decoded = encoder.decode(tokens)
print(decoded)  # "I love AI!"
```

**ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ**

- **æˆæœ¬è®¡ç®—**: API æŒ‰ token è®¡è´¹
- **ä¸Šä¸‹æ–‡é™åˆ¶**: æ¨¡å‹æœ‰ token çª—å£é™åˆ¶ï¼ˆå¦‚ GPT-4: 8K/32K/128Kï¼‰
- **æ€§èƒ½ä¼˜åŒ–**: å‡å°‘ token æ•°é‡å¯é™ä½å»¶è¿Ÿ

---

#### 1.3 æ³¨æ„åŠ›æœºåˆ¶ (Attention Mechanism)

**æ ¸å¿ƒä½œç”¨**

åœ¨ç”Ÿæˆä¸‹ä¸€ä¸ª token æ—¶ï¼Œ**åŠ¨æ€è®¡ç®—å†å² token çš„é‡è¦æ€§æƒé‡**ã€‚

**å·¥ä½œåŸç†ï¼ˆç®€åŒ–ç‰ˆï¼‰**

```
è¾“å…¥åºåˆ—: ["The", "cat", "sat", "on", "the", "mat"]
                                              â†‘
                                         å½“å‰ä½ç½®

æ³¨æ„åŠ›æƒé‡åˆ†å¸ƒ:
The  â†’ 0.05
cat  â†’ 0.35  â† é«˜æƒé‡ï¼ˆä¸»è¯­ï¼‰
sat  â†’ 0.10
on   â†’ 0.05
the  â†’ 0.40  â† é«˜æƒé‡ï¼ˆæŒ‡ä»£å…³ç³»ï¼‰
mat  â†’ 0.05
```

**å®é™…æ•ˆæœ**

- âœ… æ¨¡å‹èƒ½"å…³æ³¨"å…³é”®ä¿¡æ¯ï¼ˆå¦‚ä¸»è¯­ã€å®¾è¯­ï¼‰
- âœ… é•¿ä¸Šä¸‹æ–‡ä¸­ä»å¯ä¿æŒå…³è”ï¼ˆå¦‚ä»£è¯æŒ‡ä»£ï¼‰
- âœ… æ”¯æŒå¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Headï¼‰ï¼Œæ•è·ä¸åŒç±»å‹çš„å…³ç³»

**æŠ€æœ¯ç»†èŠ‚**

```python
# ç®€åŒ–çš„æ³¨æ„åŠ›è®¡ç®—å…¬å¼
Attention(Q, K, V) = softmax(QÂ·K^T / âˆšd_k) Â· V

# Q: Queryï¼ˆæŸ¥è¯¢ï¼‰
# K: Keyï¼ˆé”®ï¼‰
# V: Valueï¼ˆå€¼ï¼‰
# d_k: ç¼©æ”¾å› å­
```

---

### 2. Prompt Engineering vs Context Engineering

#### 2.1 æ ¸å¿ƒæ¦‚å¿µå¯¹æ¯”

| ç»´åº¦ | Prompt Engineering | Context Engineering |
|------|-------------------|---------------------|
| **æ§åˆ¶å¯¹è±¡** | è¡Œä¸º | ä¿¡æ¯ |
| **è§£å†³é—®é¢˜** | æ€ä¹ˆç­” | åŸºäºä»€ä¹ˆç­” |
| **å¯¹å¹»è§‰å½±å“** | é—´æ¥ï¼ˆçº¦æŸè¾“å‡ºæ ¼å¼ï¼‰ | ç›´æ¥ï¼ˆæä¾›äº‹å®ä¾æ®ï¼‰ |
| **å·¥ç¨‹ä½ç½®** | æŒ‡ä»¤å±‚ | æ•°æ®å±‚ |
| **å…¸å‹æŠ€æœ¯** | Few-shot, CoT | RAG, å·¥å…·è°ƒç”¨ |

---

#### 2.2 Prompt Engineering

**å…³æ³¨ç‚¹**: æ¨¡å‹**å¦‚ä½•å›ç­”**

**è§£å†³çš„é—®é¢˜**

- è¡Œä¸ºçº¦æŸï¼ˆå¦‚ï¼šä¸ä½¿ç”¨è¢«åŠ¨è¯­æ€ï¼‰
- è¾“å‡ºç»“æ„ï¼ˆå¦‚ï¼šJSON æ ¼å¼ï¼‰
- è¯­æ°”ä¸é£æ ¼ï¼ˆå¦‚ï¼šä¸“ä¸š/å‹å¥½ï¼‰

**æŠ€æœ¯ç¤ºä¾‹**

```markdown
âŒ å¼± Prompt:
"åˆ†æè¿™ä¸ªæ•°æ®"

âœ… å¼º Prompt:
**Role**: Senior Data Analyst
**Task**: Analyze Q3 sales data
**Output Format**: 
{
  "trend": "string",
  "top_products": ["array"],
  "recommendations": ["array"]
}
**Constraints**: Use only data provided, no assumptions.
```

---

#### 2.3 Context Engineering

**å…³æ³¨ç‚¹**: æ¨¡å‹**åŸºäºä»€ä¹ˆä¿¡æ¯å›ç­”**

**è§£å†³çš„é—®é¢˜**

- å‡å°‘å¹»è§‰ï¼ˆHallucinationï¼‰
- æä¾›äº‹å®ä¾æ®
- å®æ—¶ä¿¡æ¯æ³¨å…¥

**å¸¸è§æ–¹å¼**

1. **æ–‡æ¡£æ³¨å…¥**
   ```
   Context: """
   [å…¬å¸å†…éƒ¨æ–‡æ¡£å†…å®¹]
   """
   Question: æˆ‘ä»¬çš„é€€è´§æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ
   ```

2. **RAG (Retrieval-Augmented Generation)**
   ```
   æ£€ç´¢ç›¸å…³æ–‡æ¡£ â†’ æ³¨å…¥ Context â†’ LLM ç”Ÿæˆç­”æ¡ˆ
   ```

3. **å·¥å…·/API è¾“å‡ºå›çŒ**
   ```python
   # 1. LLM ç”Ÿæˆ SQL
   sql = llm.generate("æŸ¥è¯¢ä¸Šæœˆé”€å”®é¢")
   
   # 2. æ‰§è¡ŒæŸ¥è¯¢
   result = database.execute(sql)
   
   # 3. å›çŒç»“æœ
   answer = llm.generate(f"åŸºäºæ•°æ® {result}ï¼Œæ€»ç»“é”€å”®æƒ…å†µ")
   ```

---

### 3. åŸºæœ¬é…ç½®å‚æ•° (Generation Settings)

#### 3.1 Temperature (æ¸©åº¦)

**ä½œç”¨**: æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§/åˆ›é€ æ€§

**æ•°å€¼èŒƒå›´**: 0.0 ~ 2.0ï¼ˆé€šå¸¸ä½¿ç”¨ 0.0 ~ 1.0ï¼‰

**æ¨èç†è§£**

| æ¸©åº¦å€¼ | ç‰¹æ€§ | é€‚ç”¨åœºæ™¯ |
|--------|------|----------|
| 0.0 ~ 0.3 | ç¡®å®šæ€§å¼ºã€å¯å¤ç° | ä»£ç ç”Ÿæˆã€æ•°æ®æå– |
| 0.4 ~ 0.7 | å¹³è¡¡ | é€šç”¨å¯¹è¯ã€é—®ç­” |
| 0.8 ~ 1.0+ | åˆ›é€ æ€§é«˜ã€å¤šæ ·æ€§ | åˆ›æ„å†™ä½œã€å¤´è„‘é£æš´ |

**æŠ€æœ¯åŸç†**

```python
# æ¸©åº¦è°ƒæ•´ logitsï¼ˆæœªå½’ä¸€åŒ–çš„æ¦‚ç‡ï¼‰
adjusted_logits = original_logits / temperature

# temperature â†“ â†’ æ¦‚ç‡åˆ†å¸ƒæ›´å°–é”ï¼ˆç¡®å®šæ€§â†‘ï¼‰
# temperature â†‘ â†’ æ¦‚ç‡åˆ†å¸ƒæ›´å¹³å¦ï¼ˆéšæœºæ€§â†‘ï¼‰
```

---

#### 3.2 Top-K Sampling

**ä½œç”¨**: ä»…ä»æ¦‚ç‡æœ€é«˜çš„ K ä¸ª token ä¸­é‡‡æ ·

**ç¤ºä¾‹**

```
åŸå§‹æ¦‚ç‡åˆ†å¸ƒ:
token_1: 0.40
token_2: 0.30
token_3: 0.15
token_4: 0.10
token_5: 0.05

Top-K=2 â†’ ä»…ä» [token_1, token_2] ä¸­é‡‡æ ·
```

**ä¼˜åŠ¿**

- âœ… é™åˆ¶ä½è´¨é‡ token
- âœ… æé«˜è¾“å‡ºç¨³å®šæ€§

**åŠ£åŠ¿**

- âŒ å›ºå®š K å€¼ä¸é€‚åº”åŠ¨æ€åœºæ™¯

---

#### 3.3 Top-P (Nucleus Sampling)

**ä½œç”¨**: ä»ç´¯è®¡æ¦‚ç‡ â‰¥ P çš„ token é›†åˆä¸­é‡‡æ ·

**ç¤ºä¾‹**

```
Top-P=0.9

ç´¯è®¡æ¦‚ç‡:
token_1: 0.40 â†’ ç´¯è®¡ 0.40
token_2: 0.30 â†’ ç´¯è®¡ 0.70
token_3: 0.15 â†’ ç´¯è®¡ 0.85
token_4: 0.10 â†’ ç´¯è®¡ 0.95 â† è¶…è¿‡ 0.9ï¼Œåœæ­¢

é‡‡æ ·èŒƒå›´: [token_1, token_2, token_3, token_4]
```

**ç‰¹ç‚¹**

- âœ… è‡ªé€‚åº”ï¼ˆé«˜ç¡®å®šæ€§æ—¶é€‰æ‹©å°‘ï¼Œä½ç¡®å®šæ€§æ—¶é€‰æ‹©å¤šï¼‰
- âœ… å½“å‰ä¸»æµæ¨èï¼ˆOpenAI é»˜è®¤ä½¿ç”¨ï¼‰

---

#### 3.4 Token Limits

**æ§åˆ¶å†…å®¹**

- **Max Tokens**: æœ€å¤§è¾“å‡ºé•¿åº¦
- **Context Window**: è¾“å…¥+è¾“å‡ºæ€»é•¿åº¦é™åˆ¶

**å®é™…å½±å“**

| å‚æ•° | å½±å“ | æœ€ä½³å®è·µ |
|------|------|----------|
| è¾“å‡ºé•¿åº¦ | æˆæœ¬ã€å»¶è¿Ÿ | è®¾ç½®åˆç†ä¸Šé™ï¼ˆå¦‚æ‘˜è¦ä»»åŠ¡ï¼š200 tokensï¼‰ |
| ä¸Šä¸‹æ–‡çª—å£ | ä¿¡æ¯å®Œæ•´æ€§ | ç›‘æ§ token ä½¿ç”¨ç‡ï¼Œé¿å…æˆªæ–­ |

**æˆæœ¬è®¡ç®—ç¤ºä¾‹**

```python
# GPT-4 å®šä»·ï¼ˆç¤ºä¾‹ï¼‰
input_cost = 0.03 / 1000  # $0.03 per 1K tokens
output_cost = 0.06 / 1000  # $0.06 per 1K tokens

# å•æ¬¡è¯·æ±‚æˆæœ¬
input_tokens = 500
output_tokens = 200

total_cost = (input_tokens * input_cost) + (output_tokens * output_cost)
# = (500 * 0.00003) + (200 * 0.00006)
# = $0.027
```

---

## ğŸŒ¤ï¸ ä¸‹åˆä»»åŠ¡ï¼šæç¤ºæŠ€æœ¯å®è·µ

### 4. Zero-shot Prompting (é›¶æ ·æœ¬)

#### å®šä¹‰

**ä¸æä¾›ä»»ä½•ç¤ºä¾‹**ï¼Œä»…é€šè¿‡æŒ‡ä»¤æè¿°ä»»åŠ¡ã€‚

#### æŠ€æœ¯ç¤ºä¾‹

```markdown
è¯·å°†ä»¥ä¸‹æ–‡æœ¬åˆ†ç±»ä¸ºï¼šæ­£é¢ã€è´Ÿé¢ã€ä¸­æ€§ã€‚

æ–‡æœ¬: "è¿™ä¸ªäº§å“è´¨é‡ä¸€èˆ¬ï¼Œä»·æ ¼åé«˜ã€‚"
```

#### é€‚ç”¨åœºæ™¯

| åœºæ™¯ç±»å‹ | è¯´æ˜ |
|----------|------|
| âœ… ç®€å•ä»»åŠ¡ | æƒ…æ„Ÿåˆ†ç±»ã€å…³é”®è¯æå– |
| âœ… è¯­ä¹‰æ˜ç¡® | æŒ‡ä»¤æ— æ­§ä¹‰ |
| âœ… é€šç”¨èƒ½åŠ› | æ¨¡å‹é¢„è®­ç»ƒå·²è¦†ç›– |

#### ä¼˜åŠ¿ä¸åŠ£åŠ¿

**ä¼˜åŠ¿**

- æˆæœ¬æœ€ä½ï¼ˆtoken æ¶ˆè€—å°‘ï¼‰
- é€Ÿåº¦æœ€å¿«
- é€‚åˆæ¢ç´¢é˜¶æ®µ

**åŠ£åŠ¿**

- è¾“å‡ºæ ¼å¼ä¸ç¨³å®š
- å¤æ‚ä»»åŠ¡è¡¨ç°å·®

---

### 5. One-shot Prompting (å•æ ·æœ¬)

#### å®šä¹‰

æä¾› **1 ä¸ªç¤ºä¾‹** ä½œä¸ºå‚è€ƒã€‚

#### æŠ€æœ¯ç¤ºä¾‹

```markdown
ç¤ºä¾‹:
è¾“å…¥: "ä»Šå¤©ä¸‹é›¨äº†ã€‚"
è¾“å‡º: {"weather": "rainy", "sentiment": "neutral"}

è¯·æŒ‰ç›¸åŒæ ¼å¼å¤„ç†:
è¾“å…¥: "é˜³å…‰æ˜åªš,å¿ƒæƒ…æ„‰æ‚¦ã€‚"
```

#### é€‚ç”¨åœºæ™¯

| åœºæ™¯ç±»å‹ | è¯´æ˜ |
|----------|------|
| âœ… æ ¼å¼å¯¹é½ | éœ€è¦ç‰¹å®š JSON/XML ç»“æ„ |
| âœ… æ¨¡å¼ç¨³å®š | è¾“å…¥è¾“å‡ºå…³ç³»æ˜ç¡® |
| âœ… æˆæœ¬æ•æ„Ÿ | æ¯” Few-shot æ›´ç»æµ |

#### å·¥ç¨‹å®è·µ

```python
# æ¨¡æ¿åŒ– One-shot Prompt
TEMPLATE = """
Example:
Input: {example_input}
Output: {example_output}

Now process:
Input: {user_input}
"""

prompt = TEMPLATE.format(
    example_input="Cancel my order #12345",
    example_output='{"action": "cancel_order", "order_id": "12345"}',
    user_input="Refund order #67890"
)
```

---

### 6. Few-shot Prompting (å°‘æ ·æœ¬)

#### å®šä¹‰

æä¾› **å¤šä¸ªç¤ºä¾‹ï¼ˆé€šå¸¸ 2-5 ä¸ªï¼‰**ã€‚

#### æŠ€æœ¯ç¤ºä¾‹

```markdown
ç¤ºä¾‹ 1:
Q: è‹¹æœæ˜¯ä»€ä¹ˆ?
A: æ°´æœ

ç¤ºä¾‹ 2:
Q: æ±½è½¦æ˜¯ä»€ä¹ˆ?
A: äº¤é€šå·¥å…·

ç¤ºä¾‹ 3:
Q: Python æ˜¯ä»€ä¹ˆ?
A: ç¼–ç¨‹è¯­è¨€

è¯·å›ç­”:
Q: Docker æ˜¯ä»€ä¹ˆ?
```

#### é€‚ç”¨åœºæ™¯

| åœºæ™¯ç±»å‹ | è¯´æ˜ |
|----------|------|
| âœ… å¤æ‚æ¨¡å¼ | éœ€è¦å­¦ä¹ è¾“å…¥è¾“å‡ºæ˜ å°„ |
| âœ… åˆ†ç±»ä»»åŠ¡ | å¤šç±»åˆ«åˆ†ç±» |
| âœ… é£æ ¼ç»Ÿä¸€ | ä¿æŒè¾“å‡ºä¸€è‡´æ€§ |

#### ç¤ºä¾‹æ•°é‡é€‰æ‹©ç­–ç•¥

```
ä»»åŠ¡å¤æ‚åº¦ â†’ ç¤ºä¾‹æ•°é‡
â”œâ”€ ç®€å•æ ¼å¼è½¬æ¢: 1-2 ä¸ª
â”œâ”€ å¤šç±»åˆ«åˆ†ç±»: æ¯ç±» 1-2 ä¸ª
â”œâ”€ å¤æ‚æ¨ç†: 3-5 ä¸ª
â””â”€ è¾¹ç•Œæƒ…å†µ: åŒ…å«å¼‚å¸¸ç¤ºä¾‹
```

#### å·¥ç¨‹æœ€ä½³å®è·µ

```python
# åŠ¨æ€ Few-shot ç¤ºä¾‹é€‰æ‹©ï¼ˆåŸºäºç›¸ä¼¼åº¦ï¼‰
from sklearn.metrics.pairwise import cosine_similarity

def select_examples(user_query, example_pool, k=3):
    """é€‰æ‹©ä¸ç”¨æˆ·æŸ¥è¯¢æœ€ç›¸ä¼¼çš„ k ä¸ªç¤ºä¾‹"""
    similarities = cosine_similarity(
        [embed(user_query)],
        [embed(ex['query']) for ex in example_pool]
    )[0]
    
    top_k_indices = similarities.argsort()[-k:][::-1]
    return [example_pool[i] for i in top_k_indices]
```

---

## ğŸŒ™ æ™šä¸Šä»»åŠ¡ï¼šæ€»ç»“ä¸åœºæ™¯æ˜ å°„

### 7. æç¤ºæŠ€æœ¯é€‚ç”¨åœºæ™¯æ€»ç»“

#### å¯¹æ¯”çŸ©é˜µ

| æŠ€æœ¯ | æˆæœ¬ | ç¨³å®šæ€§ | å¤æ‚åº¦æ”¯æŒ | å…¸å‹åœºæ™¯ |
|------|------|--------|------------|----------|
| **Zero-shot** | â­ | â­â­ | â­ | ç®€å•åˆ†ç±»ã€é€šç”¨é—®ç­” |
| **One-shot** | â­â­ | â­â­â­ | â­â­ | æ ¼å¼åŒ–è¾“å‡ºã€API è°ƒç”¨ |
| **Few-shot** | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | å¤æ‚åˆ†ç±»ã€é£æ ¼è¿ç§» |

#### å†³ç­–æ ‘

```mermaid
graph TD
    A[å¼€å§‹] --> B{ä»»åŠ¡æ˜¯å¦ç®€å•?}
    B -->|æ˜¯| C{è¾“å‡ºæ ¼å¼é‡è¦?}
    B -->|å¦| D[Few-shot]
    C -->|å¦| E[Zero-shot]
    C -->|æ˜¯| F{æˆæœ¬æ•æ„Ÿ?}
    F -->|æ˜¯| G[One-shot]
    F -->|å¦| D
```

---

### 8. å¸¸è§æ•…éšœæ¨¡å¼ä¸ä¿®æ­£ç­–ç•¥

#### æ•…éšœæ¨¡å¼è¡¨

| æ•…éšœæ¨¡å¼ | è¡¨ç°ç‰¹å¾ | æŠ€æœ¯å½’å›  | ä¿®æ­£ç­–ç•¥ |
|----------|----------|----------|----------|
| **æ¨¡ç³ŠæŒ‡ä»¤** | è¾“å‡ºéšæœºæ€§é«˜ | Logits åˆ†å¸ƒè¿‡äºå¹³å¦ | å¼•å…¥ Few-shot ç¤ºä¾‹ |
| **è´Ÿå‘çº¦æŸé™·é˜±** | é¢‘ç¹è¿å"ç¦æ­¢"æŒ‡ä»¤ | æ³¨æ„åŠ›æœºåˆ¶å…³æ³¨å‡ºç°çš„ token | æ”¹ä¸ºæ­£å‘æŒ‡ä»¤ |
| **ä¸Šä¸‹æ–‡è¿‡è½½** | å…³é”®ä¿¡æ¯è¢«å¿½ç•¥ | "Lost in the Middle" ç°è±¡ | æ ¸å¿ƒæŒ‡ä»¤ç½®äºå¼€å¤´/ç»“å°¾ |
| **å·¥å…·å¹»è§‰** | è°ƒç”¨ä¸å­˜åœ¨çš„ API | è¿‡åº¦æ‹Ÿåˆå·¥å…·æ¨¡å¼ | æä¾›ä¸¥æ ¼çš„ API Schema |

#### å®æˆ˜æ¡ˆä¾‹ï¼šè´Ÿå‘çº¦æŸé™·é˜±

```markdown
âŒ é”™è¯¯ç¤ºä¾‹:
"ä¸è¦ä½¿ç”¨è¢«åŠ¨è¯­æ€ï¼Œä¸è¦è¶…è¿‡ 100 å­—ã€‚"

âœ… æ­£ç¡®ç¤ºä¾‹:
"è¯·ä½¿ç”¨ä¸»åŠ¨è¯­æ€ï¼Œæ§åˆ¶åœ¨ 100 å­—ä»¥å†…ã€‚"
```

---

## ğŸ¯ å…³é”®è®¤çŸ¥æ€»ç»“ (Key Takeaways)

### æ ¸å¿ƒåŸåˆ™

1. **LLM çš„æœ¬è´¨**: Token çº§æ¦‚ç‡é¢„æµ‹æ¨¡å‹
2. **å·¥ç¨‹åˆ†ç¦»**: Prompt å†³å®šè¡Œä¸ºï¼ŒContext å†³å®šäº‹å®
3. **å‚æ•°ç†è§£**: æ§åˆ¶çš„æ˜¯"è¾“å‡ºè¡Œä¸º"ï¼Œä¸æ˜¯æ¨¡å‹èƒ½åŠ›
4. **ç¤ºä¾‹æƒè¡¡**: æ•°é‡è¶Šå¤šè¶Šç¨³å®šï¼Œä½†æˆæœ¬è¶Šé«˜
5. **å·¥ç¨‹ä¼˜å…ˆçº§**:
   - æ˜ç¡®æŒ‡ä»¤ï¼ˆåŠ¨è¯å…·ä½“åŒ–ï¼‰
   - ç»“æ„åŒ–è¾“å‡ºï¼ˆJSON/XMLï¼‰
   - æœ€å°å¯ç”¨ç¤ºä¾‹é›†ï¼ˆæˆæœ¬ä¼˜åŒ–ï¼‰

---

### æŠ€æœ¯å€ºåŠ¡è­¦ç¤º

> âš ï¸ **å¸¸è§åæ¨¡å¼**
> 
> - è¿‡åº¦ä¾èµ–é«˜ temperatureï¼ˆåº”ä¼˜å…ˆä¼˜åŒ– Promptï¼‰
> - å¿½ç•¥ token æˆæœ¬ï¼ˆåº”ç›‘æ§å¹¶ä¼˜åŒ–ï¼‰
> - ç¼ºå°‘è¾“å‡ºéªŒè¯ï¼ˆåº”å®ç° Schema æ ¡éªŒï¼‰

---

## ğŸ“š è¿›é˜¶å­¦ä¹ è·¯å¾„

### ä¸‹ä¸€æ­¥å»ºè®®

#### 1. Prompt æ¨¡æ¿åŒ–

```python
# å°† Prompt æŠ½è±¡ä¸ºå¯å¤ç”¨æ¨¡æ¿
class PromptTemplate:
    def __init__(self, template: str):
        self.template = template
    
    def format(self, **kwargs) -> str:
        return self.template.format(**kwargs)

# ä½¿ç”¨ç¤ºä¾‹
sql_template = PromptTemplate("""
Schema: {schema}
Task: {task}
Output: SQL query only
""")

prompt = sql_template.format(
    schema="users(id, name, email)",
    task="Find all users registered in 2024"
)
```

#### 2. å¼•å…¥ Context Engineering

```python
# RAG åŸºç¡€å®ç°
def rag_query(question: str):
    # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    docs = vector_db.search(question, top_k=3)
    
    # 2. æ„å»º Context
    context = "\n".join([doc.content for doc in docs])
    
    # 3. ç”Ÿæˆç­”æ¡ˆ
    prompt = f"""
    Context: {context}
    
    Question: {question}
    
    Answer based only on the context above.
    """
    
    return llm.generate(prompt)
```

#### 3. å¤šæ­¥ Prompt (Chain-of-Thought)

```markdown
Let's solve this step by step:

1. **Understand the problem**: [é—®é¢˜åˆ†æ]
2. **Identify key information**: [å…³é”®ä¿¡æ¯æå–]
3. **Apply reasoning**: [æ¨ç†è¿‡ç¨‹]
4. **Verify the answer**: [éªŒè¯]
5. **Final answer**: [æœ€ç»ˆç­”æ¡ˆ]
```

#### 4. Prompt è¯„å®¡ä¸æµ‹è¯•æœºåˆ¶

```python
# è‡ªåŠ¨åŒ– Prompt æµ‹è¯•
test_cases = [
    {"input": "...", "expected_output": "..."},
    {"input": "...", "expected_output": "..."},
]

def evaluate_prompt(prompt_template, test_cases):
    results = []
    for case in test_cases:
        output = llm.generate(prompt_template.format(**case['input']))
        score = similarity(output, case['expected_output'])
        results.append(score)
    
    return sum(results) / len(results)
```

---

## ğŸ”— å‚è€ƒèµ„æº

### æ¨èé˜…è¯»

- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Engineering Tutorial](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [Weak vs. Perfect Prompt: Python Example](https://www.youtube.com/shorts/mUxWL9748BE)

### å·¥å…·æ¨è

- **Tokenizer**: [tiktoken](https://github.com/openai/tiktoken)
- **Prompt ç®¡ç†**: [LangChain](https://github.com/langchain-ai/langchain)
- **æµ‹è¯•æ¡†æ¶**: [PromptFoo](https://github.com/promptfoo/promptfoo)

---

## âœ… ä»Šæ—¥å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£ Transformer æ¶æ„çš„æ ¸å¿ƒç»„ä»¶
- [ ] æŒæ¡ Token çš„æ¦‚å¿µåŠå…¶å¯¹æˆæœ¬çš„å½±å“
- [ ] åŒºåˆ† Prompt Engineering ä¸ Context Engineering
- [ ] ç†Ÿæ‚‰ temperature, top-K, top-P å‚æ•°çš„ä½œç”¨
- [ ] å®è·µ Zero-shot, One-shot, Few-shot æç¤ºæŠ€æœ¯
- [ ] èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡é€‰æ‹©åˆé€‚çš„æç¤ºç­–ç•¥
- [ ] è¯†åˆ«å¹¶ä¿®æ­£å¸¸è§çš„ Prompt åæ¨¡å¼

---

**æ­å–œå®Œæˆ Day 1 å­¦ä¹ ï¼ğŸ‰**

æ˜å¤©æˆ‘ä»¬å°†æ·±å…¥å­¦ä¹ ï¼š
- Chain-of-Thought (CoT) æ¨ç†
- ReAct æ¨¡å¼
- å·¥å…·è°ƒç”¨ (Function Calling)
- Agent æ¶æ„åŸºç¡€
